import os
from pathlib import Path
from my_sdk.core.interfaces import PipelineStep, ReconstructionContext
from my_sdk.utils.docker_runner import DockerRunner
from my_sdk.utils.opensfm_exporter import convert_opensfm_to_nerf

class GSToPCAdapter(PipelineStep):
    """
    Adapter for 3DGS-to-PC tool.
    Converts Gaussian Splatting (.ply) models to dense point clouds (.ply).
    """

    @property
    def name(self) -> str:
        return "Process: 3DGS to Point Cloud"

    def run(self, context: ReconstructionContext) -> bool:
        print("[GS2PC] Starting conversion from Gaussian Splatting to Point Cloud...")

        # 1. Check for expected input (OpenSplat output)
        gsl_output_dir = context.run_dir / "3d_gsl"
        input_ply = gsl_output_dir / "splat.ply"
        output_dense_pc = gsl_output_dir / "dense_pc.ply"

        # Resume support: Check if already converted
        if output_dense_pc.exists():
            print(f"[GS2PC] Found existing dense point cloud at {output_dense_pc}. Skipping conversion.")
            return True

        if not input_ply.exists():
            print(f"[GS2PC] Error: Input Gaussian model not found at {input_ply}. Ensure Gaussian Splatting step finished successfully.")
            return False

        # 2. Verify NeRF transforms.json availability
        # This is now generated by default after SfM at the run root.
        reconstruction_json = context.run_dir / "opensfm" / "reconstruction.json"
        transforms_json = context.run_dir / "transforms.json"
        
        if not transforms_json.exists():
            # Fallback if SfM stage was skipped or failed to export
            if reconstruction_json.exists():
                print(f"[GS2PC] {transforms_json.name} missing, performing on-the-fly conversion from {reconstruction_json.name}...")
                convert_opensfm_to_nerf(reconstruction_json, transforms_json, images_relative_path="../../images")
            else:
                print("[GS2PC] Error: Missing SfM data (reconstruction.json) required for conversion.")
                return False

        # 3. Setup DockerRunner
        runner = DockerRunner()
        
        # 3. Construct Docker Command with DooD
        host_data_dir = os.environ.get("HOST_DATA_DIR")
        if not host_data_dir:
            raise ValueError("HOST_DATA_DIR environment variable is missing. Required for DooD.")

        rel_run_path = context.run_dir.relative_to(context.config.working_dir)
        host_run_dir = Path(host_data_dir) / rel_run_path
        
        # In container paths (same as opensplat for consistency)
        container_project = "/project"
        container_input = f"{container_project}/3d_gsl/splat.ply"
        container_output = f"{container_project}/3d_gsl/dense_pc.ply"
        
        docker_image = context.config.algorithms.gs_to_pc_docker_image
        
        # Check GPU availability
        use_gpu = DockerRunner.check_gpu_support()
        
        command = [
            "docker", "run", "--rm",
            "-v", f"{host_run_dir}:{container_project}",
            "-e", "NVIDIA_VISIBLE_DEVICES=all",
            "-e", "NVIDIA_DRIVER_CAPABILITIES=all",
            docker_image,
            "--input_path", container_input,
            "--output_path", container_output,
            # Use the newly generated transforms.json at root
            "--transform_path", f"{container_project}/transforms.json"
        ]

        if use_gpu:
            command.insert(2, "--gpus")
            command.insert(3, "all")

        # Add custom params.
        # Keep GS2PC SH degree in sync with OpenSplat output by default to avoid
        # loader assertions when OpenSplat is not using degree=3.
        user_params = dict(context.config.params.get("gs_to_pc", {}))
        if "max_sh_degree" not in user_params:
            effective_sh_degree = context.config.sh_degree
            opensplat_overrides = context.config.params.get("opensplat", {})
            if "sh-degree" in opensplat_overrides:
                effective_sh_degree = int(opensplat_overrides["sh-degree"])
            elif "sh_degree" in opensplat_overrides:
                effective_sh_degree = int(opensplat_overrides["sh_degree"])

            user_params["max_sh_degree"] = int(effective_sh_degree)

        for k, v in user_params.items():
            command.extend([f"--{k}", str(v)])

        # 4. Execute
        success = runner.run(command, step_name="GS2PC")
        
        if success:
            print(f"[GS2PC] Conversion finished. Dense point cloud at {output_dense_pc}")
            self._extract_metrics(context)
            
        return success

    def _extract_metrics(self, context: ReconstructionContext):
        """Extract points count from the generated PLY file."""
        import re
        dense_pc = context.run_dir / "3d_gsl" / "dense_pc.ply"
        if dense_pc.exists():
            try:
                with open(dense_pc, "rb") as f:
                    header = f.read(2048).decode(errors='ignore')
                    v_match = re.search(r"element vertex (\d+)", header)
                    if v_match:
                        context.metrics.setdefault("gs_to_pc", {})["point_count"] = int(v_match.group(1))
            except Exception as e:
                print(f"[GS2PC] Warning: Could not parse PLY header: {e}")
